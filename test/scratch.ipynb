{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'y_Actual':    list(y_test.values),\n",
    "        'y_Predicted': list(prediction_test)}\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "# this code is edited rest us untouched\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "ax = sns.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom+0.5, top-0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Something wrong with the visualization \n",
    "import itertools\n",
    "\n",
    "# Create the basic matrix\n",
    "#cnf_matrix=confusion_matrix(y_test, prediction_test)\n",
    "#plt.imshow(cnf_matrix,  cmap=plt.cm.Blues) \n",
    "\n",
    "# Add title and axis labels\n",
    "#plt.title('Confusion Matrix')\n",
    "#plt.ylabel('True label')\n",
    "#plt.xlabel('Predicted label')\n",
    "\n",
    "# Add appropriate axis scales\n",
    "#class_names = set(y) # Get class labels to add to matrix\n",
    "#tick_marks = np.arange(len(class_names))\n",
    "#plt.xticks(tick_marks, class_names)\n",
    "#plt.yticks(tick_marks, class_names)\n",
    "\n",
    "# Add labels to each cell\n",
    "#thresh = cnf_matrix.max() / 2. # Used for text coloring below\n",
    "# Here we iterate through the confusion matrix and append labels to our visualization \n",
    "#for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "#        plt.text(j, i, cnf_matrix[i, j],\n",
    "#                 horizontalalignment='center',\n",
    "#                 color='white' if cnf_matrix[i, j] > thresh else 'black')\n",
    "\n",
    "# Add a legend\n",
    "#plt.colorbar()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst    = [logit,decision_tree,knn,rfc,\n",
    "          gnb,svc_lin,xgc]\n",
    "\n",
    "length = len(lst)\n",
    "\n",
    "mods   = ['Logistic Regression(Baseline_model)',\n",
    "          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n",
    "          'SVM Classifier Linear','XGBoost Classifier']\n",
    "\n",
    "fig = plt.figure(figsize=(13,15))\n",
    "fig.set_facecolor(\"#F3F3F3\")\n",
    "for i,j,k in itertools.zip_longest(lst,range(length),mods) :\n",
    "    plt.subplot(4,3,j+1)\n",
    "    predictions = i.predict(X_test)\n",
    "    conf_matrix = confusion_matrix(predictions,y_test)\n",
    "    sns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n",
    "                xticklabels=[\"not churn\",\"churn\"],\n",
    "                yticklabels=[\"not churn\",\"churn\"],\n",
    "                linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
    "    plt.title(k,color = \"b\")\n",
    "    plt.subplots_adjust(wspace = .3,hspace = .3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst    = [logit,decision_tree,knn,rfc,\n",
    "          gnb,svc_lin,xgc]\n",
    "\n",
    "length = len(lst)\n",
    "\n",
    "mods   = ['Logistic Regression(Baseline_model)',\n",
    "          'Decision Tree','KNN Classifier','Random Forest Classifier',\"Naive Bayes\",\n",
    "          'SVM Classifier Linear','XGBoost Classifier']\n",
    "\n",
    "fig = plt.figure(figsize=(13,15))\n",
    "#fig.set_facecolor(\"#F3F3F3\")\n",
    "for i,j,k in itertools.zip_longest(lst,range(length),mods) :\n",
    "    fig, ax = plt.subplots(4,3,j+1)\n",
    "    predictions = i.predict(X_test)\n",
    "    data = {'y_Actual': list(y_test.values),\n",
    "        'y_Predicted': list(predictions)}\n",
    "    df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "    confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "    ax = sns.heatmap(confusion_matrix, annot=True, fmt='g')\n",
    "    plt.title(k,color = \"b\")\n",
    "    plt.subplots_adjust(wspace = .3,hspace = .3)\n",
    "    bottom, top = ax.get_ylim()\n",
    "    ax.set_ylim(bottom+0.5, top-0.5)\n",
    "    \n",
    "    \n",
    "    #sns.heatmap(conf_matrix,annot=True,fmt = \"d\",square = True,\n",
    "    #            xticklabels=[\"not churn\",\"churn\"],\n",
    "    #            yticklabels=[\"not churn\",\"churn\"],\n",
    "    #            linewidths = 2,linecolor = \"w\",cmap = \"Set1\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a baseline model for all models \n",
    "logit = LogisticRegression()\n",
    "model1 = model_report(logit,X_train_resampled,X_test,y_train_resampled,y_test,\n",
    "                      \"Logistic Regression(Baseline_model)\")\n",
    "decision_tree = DecisionTreeClassifier(max_depth = 9,\n",
    "                                       random_state = 123,\n",
    "                                       splitter  = \"best\",\n",
    "                                       criterion = \"gini\",\n",
    "                                      )\n",
    "model2 = model_report(decision_tree,X_train_resampled,X_test,y_train_resampled,y_test,\n",
    "                      \"Decision Tree\")\n",
    "knn = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
    "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
    "           weights='uniform')\n",
    "\n",
    "model3 = model_report(knn,X_train_resampled,X_test,y_train_resampled,y_test,\n",
    "                      \"KNN Classifier\")\n",
    "gnb = GaussianNB(priors=None)\n",
    "model4 = model_report(gnb,X_train_resampled,X_test,y_train_resampled,y_test,\n",
    "                      \"Naive Bayes\")\n",
    "rfc = RandomForestClassifier(n_estimators = 1000,\n",
    "                             random_state = 123,\n",
    "                             max_depth = 9,\n",
    "                             criterion = \"gini\")\n",
    "model5 = model_report(rfc,X_train_resampled,X_test,y_train_resampled,y_test,\n",
    "                      \"Random Forest Classifier\")\n",
    "svc_lin  = SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
    "               decision_function_shape='ovr', degree=3, gamma=1.0, kernel='linear',\n",
    "               max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
    "               tol=0.001, verbose=False)\n",
    "model6 = model_report(svc_lin,X_train_resampled,X_test,y_train_resampled,y_test,\n",
    "                      \"SVM Classifier Linear\")\n",
    "xgc = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "                    colsample_bytree=1, gamma=0, learning_rate=0.9, max_delta_step=0,\n",
    "                    max_depth = 7, min_child_weight=1, missing=None, n_estimators=100,\n",
    "                    n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
    "                    reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "                    silent=True, subsample=1)\n",
    "model7 = model_report(xgc,X_train_resampled,X_test,y_train_resampled,y_test,\n",
    "                      \"XGBoost Classifier\")\n",
    "\n",
    "#concat all models\n",
    "model_performances = pd.concat([model1,model2,model3,model4,\n",
    "                                model5,model6,model7],axis = 0).reset_index()\n",
    "\n",
    "model_performances = model_performances.drop(columns = \"index\",axis =1)\n",
    "display(model_performances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "#[[1596  978]\n",
    "# [ 116  826]]\n",
    "#z = [[0.1, 0.3],\n",
    "#     [1.0, 0.8]]\n",
    "z=[list(conf_matrix[i]) for i in [1,0]]\n",
    "\n",
    "#x = [\"not Churn\", \"churn\"]\n",
    "#y = [\"Churn\", \"not churn\"]\n",
    "\n",
    "# change each element of z to type string for annotations\n",
    "#z_text = [[str(y) for y in x] for x in z]\n",
    "\n",
    "# set up figure \n",
    "fig = ff.create_annotated_heatmap(z, x=[\"not Churn\", \"churn\"], y=[\"Churn\", \"not churn\"],\n",
    "                                  annotation_text=z_text, \n",
    "                                  colorscale='Viridis')\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=350,\n",
    "    height=350,\n",
    "    yaxis=dict(\n",
    "        title_text=\"Actual\",\n",
    "        tickmode=\"array\",\n",
    "        titlefont=dict(size=21)),\n",
    "    xaxis=dict(\n",
    "        title_text=\"Predics\",\n",
    "        tickmode=\"array\",\n",
    "        titlefont=dict(size=21)),\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_score_test = logreg_1.decision_function(X_test)\n",
    "test_fpr, test_tpr, test_thresholds = roc_curve(y_test, y_score_test)\n",
    "\n",
    "y_score_train = logreg_1.decision_function(X_train)\n",
    "train_fpr, train_tpr, train_thresholds = roc_curve(y_train, y_score_train)\n",
    "\n",
    "# Train AUC\n",
    "print('Train AUC: {}'.format(auc(train_fpr, train_tpr)))\n",
    "print('Test AUC: {}'.format(auc(test_fpr, test_tpr)))\n",
    "\n",
    "# Seaborn's beautiful styling\n",
    "sns.set_style('darkgrid', {'axes.facecolor': '0.9'})\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "lw = 2\n",
    "\n",
    "plt.plot(train_fpr, train_tpr, color='blue',\n",
    "         lw=lw, label='Train ROC curve')\n",
    "plt.plot(test_fpr, test_tpr, color='darkorange',\n",
    "         lw=lw, label='Test ROC curve')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.yticks([i/20.0 for i in range(21)])\n",
    "plt.xticks([i/20.0 for i in range(21)])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:learn-env] *",
   "language": "python",
   "name": "conda-env-learn-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
